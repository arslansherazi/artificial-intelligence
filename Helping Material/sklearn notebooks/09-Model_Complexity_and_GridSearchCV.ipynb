{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.532965\n",
      "n_neighbors: 3, average score: 0.733161\n",
      "n_neighbors: 5, average score: 0.701655\n",
      "n_neighbors: 10, average score: 0.720478\n",
      "n_neighbors: 20, average score: 0.632348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XlYVeX2wPHvEnHAeTanwHIGQcS5EhzSNKfKNJwTbbhN\nt25dG34Nt+Fa2TxePc7hVFZiWVqJabMIKM4jzgPOoqLAeX9/7AMcCRX1HM4B1ud5eODss9l7sS0W\ne737Xa8YY1BKKaUASng6AKWUUt5Dk4JSSqlsmhSUUkpl06SglFIqmyYFpZRS2TQpKKWUyqZJQSml\nVDZNCkoppbJpUlBKKZWtpKcDuFLVq1c3/v7+ng5DKaUKlVWrVh02xtS43H6FLin4+/sTFxfn6TCU\nUqpQEZGd+dlPy0dKKaWyaVJQSimVTZOCUkqpbIVuTCEv6enp7Nmzh7S0NE+Hoi6jTJky1KtXD19f\nX0+HopTKQ5FICnv27KFChQr4+/sjIp4OR12EMYYjR46wZ88eAgICPB2OUioPbisficgUETkkImsv\n8r6IyPsislVE1ohI6NWeKy0tjWrVqmlC8HIiQrVq1fSOTikv5s4xhWlAz0u8fxvQyPExFvjkWk6m\nCaFw0H8npbyb25KCMWY5cPQSu/QDZhjLH0BlEbnOXfEopVRRFhcHr7wCx49f23E8+fRRXWC30+s9\njm1/IyJjRSROROJSUlIKJLgrcfz4cT7++OOr+t5evXpx/Fr/FZVSxV50tJUUSl7jSHGheCTVGDPR\nGBNmjAmrUeOys7QL3KWSQkZGxiW/d9GiRVSuXNkdYV0TYwx2u93TYSil8sEYWLAAunWD8uWv7Vie\nTAp7gfpOr+s5thU648aNY9u2bYSEhPDkk0+ybNkybr75Zvr27Uvz5s0B6N+/P61bt6ZFixZMnDgx\n+3v9/f05fPgwycnJNGvWjDFjxtCiRQtuvfVWzp49+7dzLVy4kHbt2tGqVSu6devGwYMHAUhNTWXU\nqFEEBQXRsmVL5s+fD8D3339PaGgowcHBdO3aFYAXX3yRCRMmZB8zMDCQ5ORkkpOTadKkCcOHDycw\nMJDdu3fzwAMPEBYWRosWLXjhhReyv2flypV07NiR4OBg2rZty6lTp7jllltITEzM3uemm25i9erV\nLrzSSqm8rFsHO3ZA377XfixPPpIaAzwkInOAdsAJY8z+az3oY4+B0+8llwgJgXffvfj748ePZ+3a\ntdm/EJctW0Z8fDxr167NfvRyypQpVK1albNnz9KmTRvuvPNOqlWrdsFxtmzZwuzZs5k0aRJ33303\n8+fPZ+jQoRfsc9NNN/HHH38gIthsNt544w3eeustXn75ZSpVqkRSUhIAx44dIyUlhTFjxrB8+XIC\nAgI4evRSQzw5MUyfPp327dsD8Oqrr1K1alUyMzPp2rUra9asoWnTpgwaNIi5c+fSpk0bTp48Sdmy\nZRk9ejTTpk3j3XffZfPmzaSlpREcHJzv66yUujoLFlif+/S59mO5LSmIyGwgHKguInuAFwBfAGPM\np8AioBewFTgDjHJXLJ7Qtm3bC57Ff//99/nqq68A2L17N1u2bPlbUggICCAkJASA1q1bk5yc/Lfj\n7tmzh0GDBrF//37Onz+ffY4ff/yROXPmZO9XpUoVFi5cyC233JK9T9WqVS8b9/XXX5+dEADmzZvH\nxIkTycjIYP/+/axfvx4R4brrrqNNmzYAVKxYEYCBAwfy8ssv8+abbzJlyhRGjhx52fMppa5dTAy0\nbQvXueBRHbclBWPMPZd53wD/cPV5L/UXfUEqV65c9tfLli3jxx9/5Pfff8fPz4/w8PA8n9UvXbp0\n9tc+Pj55lo8efvhhHn/8cfr27cuyZct48cUXrzi2kiVLXjBe4ByLc9w7duxgwoQJrFy5kipVqjBy\n5MhLzjHw8/Oje/fuLFiwgHnz5rFq1aorjk0pdWX27YO//oJXX3XN8QrFQLO3q1ChAqdOnbro+ydO\nnKBKlSr4+fmxceNG/vjjj6s+14kTJ6hb13pIa/r06dnbu3fvzkcffZT9+tixY7Rv357ly5ezY8cO\ngOzykb+/P/Hx8QDEx8dnv5/byZMnKVeuHJUqVeLgwYN89913ADRp0oT9+/ezcuVKAE6dOpU9oB4V\nFcUjjzxCmzZtqFKlylX/nEqp/PnmG+uzK8YTQJOCS1SrVo1OnToRGBjIk08++bf3e/bsSUZGBs2a\nNWPcuHEXlGeu1IsvvsjAgQNp3bo11atXz97+3HPPcezYMQIDAwkODiY2NpYaNWowceJE7rjjDoKD\ngxk0aBAAd955J0ePHqVFixZ8+OGHNG7cOM9zBQcH06pVK5o2bUpkZCSdOnUCoFSpUsydO5eHH36Y\n4OBgunfvnn0H0bp1aypWrMioUUWqGqiU11qwABo2hBYtXHM8sao4hUdYWJjJvcjOhg0baNasmYci\nUs727dtHeHg4GzdupESJvP/m0H8vpVwjNRWqV4cHHoB33rn0viKyyhgTdrlj6p2CcpkZM2bQrl07\nXn311YsmBKWU6yxZAufOQb9+rjtmkeiSqrzD8OHDGT58uKfDUKrYiImBKlXgpptcd0z9c04ppQqh\njAxrkLl372tvbeFMk4JSShVCv/8OR4647qmjLJoUlFKqEFqwAEqVgp6XWqDgKmhSUEqpQiarAV5E\nBFSo4Npja1JwgWtpnQ3w7rvvcubMGRdGpJQqyjZuhK1bXfvUURZNCi5QFJLC5Vp8K6W8R0yM9dkV\nDfBy06TgArlbZwO8+eabtGnThpYtW2a3nD59+jS9e/cmODiYwMBA5s6dy/vvv8++ffuIiIggIiLi\nb8f+z3/+Q5s2bQgMDGTs2LFkTTbcunUr3bp1Izg4mNDQULZt2wbA66+/TlBQEMHBwYwbNw6A8PBw\nsib8HT58GH9/fwCmTZtG37596dKlC127diU1NZWuXbsSGhpKUFAQC7JaL2LNQWjZsiXBwcEMGzaM\nU6dOERAQQHp6OmC1xHB+rZRynwULoHVrqFfP9ccucvMUHvv+MRIPuLZ3dkjtEN7tefFOe7lbZy9Z\nsoQtW7bw119/YYyhb9++LF++nJSUFOrUqcO3334LWH2MKlWqxNtvv01sbOwFbSuyPPTQQzz//PMA\nDBs2jG+++YY+ffowZMgQxo0bx4ABA0hLS8Nut/Pdd9+xYMEC/vzzT/z8/PLVKjs+Pp41a9ZQtWpV\nMjIy+Oqrr6hYsSKHDx+mffv29O3bl/Xr1/PKK6/w22+/Ub16dY4ePUqFChUIDw/n22+/pX///syZ\nM4c77rgDX1/fq7nESql8OngQ/vgDrqIXZr7onYIbLFmyhCVLltCqVStCQ0PZuHEjW7ZsISgoiB9+\n+IF///vfrFixgkqVKl32WLGxsbRr146goCCWLl3KunXrOHXqFHv37mXAgAEAlClTBj8/P3788UdG\njRqFn58fkL9W2d27d8/ezxjDM888Q8uWLenWrRt79+7l4MGDLF26lIEDB2Ynraz9o6KimDp1KgBT\np07VfkdKFYBvvrEGmt0xngBF8E7hUn/RFxRjDE8//TT33Xff396Lj49n0aJFPPfcc3Tt2jX7LiAv\naWlpPPjgg8TFxVG/fn1efPHFS7auvhjnVtm5v9+5VXZ0dDQpKSmsWrUKX19f/P39L3m+Tp06kZyc\nzLJly8jMzCQwMPCKY1NKXZmYGLj+emjZ0j3H1zsFF8jdOrtHjx5MmTKF1NRUAPbu3cuhQ4fYt28f\nfn5+DB06lCeffDK7ffXFWm9n/UKuXr06qampfPHFF9n716tXj6+//hqAc+fOcebMGbp3787UqVOz\nB62dW2VnrW2QdYy8nDhxgpo1a+Lr60tsbCw7d+4EoEuXLnz++eccOXLkguOC1doiMjJS7xKUKgBn\nzsAPP1gT1kTccw5NCi6Qu3X2rbfeSmRkJB06dCAoKIi77rqLU6dOkZSURNu2bQkJCeGll17iueee\nA2Ds2LH07NnzbwPNlStXZsyYMQQGBtKjR4/slc4AZs6cyfvvv0/Lli3p2LEjBw4coGfPnvTt25ew\nsDBCQkKy12H+17/+xSeffEKrVq04fPjwRX+OIUOGEBcXR1BQEDNmzKBp06YAtGjRgmeffZbOnTsT\nHBzM448/fsH3HDt2jHvuueSaSkopF/jxRzh71vWzmJ1p62x1Tb744gsWLFjAzJkz8/09+u+l1NUZ\nPRrmz4eUFLjSZzry2zq7yI0pqILz8MMP891337Fo0SJPh6JUkZeZCQsXwm23XXlCuBKaFNRV++CD\nDzwdglLFxp9/WncI7nrqKEuRGVMobGWw4kr/nZS6OjExVotsVzfAy82tSUFEeorIJhHZKiLj8ni/\nioh8JSJrROQvEbmqZxrLlCnDkSNH9BeOlzPGcOTIEcqUKePpUJQqdBYsgPBwqFzZvedxW/lIRHyA\nj4DuwB5gpYjEGGPWO+32DJBojBkgIk0d+3e90nPVq1ePPXv2kJKS4orQlRuVKVOGeu6Ym69UEbZ5\ns9UE78EH3X8ud44ptAW2GmO2A4jIHKAf4JwUmgPjAYwxG0XEX0RqGWMOXsmJfH19CQgIcFHYSinl\nXbIa4LnzUdQs7iwf1QV2O73e49jmbDVwB4CItAWuB/TPSKWUchITA8HB1kxmd/P0QPN4oLKIJAIP\nAwlAZu6dRGSsiMSJSJyWiJRSxcnhw/Drr+5/6iiLO8tHe4H6Tq/rObZlM8acBEYBiIgAO4DtuQ9k\njJkITARr8pqb4lVKKa/z7bdgtxdM6Qjce6ewEmgkIgEiUgoYDMQ47yAilR3vAUQByx2JQimlFNZT\nR3XrQmhowZzPbXcKxpgMEXkIWAz4AFOMMetE5H7H+58CzYDpImKAdcBod8WjlFKFTVoaLF4MI0a4\nrwFebm6d0WyMWQQsyrXtU6evfwcauzMGpZQqrH76yeqMWlClI/D8QLNSSqmLiImB8uUhj5V63UaT\nglJKeSG73UoKPXtC6dIFd15NCkop5YXi4uDAgYJ7FDWLJgWllPJCCxaAjw/06lWw59WkoJRSXigm\nBm6+GapWLdjzalJQSikvs307rF1bsE8dZdGkoJRSXqYgG+DlpklBKaW8SFISTJwILVrADTcU/Pk1\nKSillBfYtQtGjrS6oe7fDy+/7Jk4NCkopZQHHTsGTz4JjRvDnDnwxBOwbRsMGOCZeNza5kIppVTe\nzp6FDz+E116DEydg+HD4z3+gQQPPxqV3CkopVYAyM2HaNGjSBJ56Cjp2hMREa5unEwJoUlBKqQJh\njLU2QkgIjBoFtWtDbKy1rWVLT0eXQ5OCUkq52Z9/Wk3tbr/daoc9b561LTzc05H9nSYFpZRyk4QE\nGDgQ2reHDRvgo49g/XprW0Gtj3CldKBZKaVcyG6H776Dt96yykPly8MLL1hPFVWo4OnoLk+TglJK\nuUBaGsycCe+8Y90V1K0Lb7wBY8ZA5cqeji7/NCkopdQ1SEmBTz6xHi9NSbEGkmfOhLvvhlKlLv/9\n3kaTglJKXYVNm6y7gunTrbuEXr2sElFEhPeOF+SHJgWllMonY2D5cmu8YOFCa0W0YcPgn/+E5s09\nHZ1raFJQSqnLSE+HL76At9+2VkSrXh2efx4efBBq1fJ0dK6lSUEppS7i5Emw2eC996yGdY0bw6ef\nWi0pypb1dHTu4dZ5CiLSU0Q2ichWERmXx/uVRGShiKwWkXUiMsqd8SilVH7s3g3/+hfUr2+NE/j7\nW8tjbtgA991XdBMCuPFOQUR8gI+A7sAeYKWIxBhj1jvt9g9gvTGmj4jUADaJSLQx5ry74lJKqYtZ\ntcoaL5g3z3o9cKCVFMLCPBtXQXJn+agtsNUYsx1AROYA/QDnpGCACiIiQHngKJDhxpiUUuoCdjss\nWgQTJsDPP1sTzB59FB55BK6/3tPRFTx3JoW6wG6n13uAdrn2+RCIAfYBFYBBxhi7G2NSSinAal09\nc6Y1eLxpE9SrB2++aU02q1TJ09F5jqcHmnsAiUAX4AbgBxFZYYw56byTiIwFxgI08IbeskqpQuvQ\nIfj4Y+sjJQVCQyE62ioV+fp6OjrPc+dA816gvtPreo5tzkYBXxrLVmAH0DT3gYwxE40xYcaYsBo1\nargtYKVU0bVxI4wda61Z8NJL0K6d1ZsoLg4iIzUhZHFnUlgJNBKRABEpBQzGKhU52wV0BRCRWkAT\nYLsbY1JKFSPGwLJlVsvqZs1gxgwYMcJ6imjhQqt1dWGefewObisfGWMyROQhYDHgA0wxxqwTkfsd\n738KvAxME5EkQIB/G2MOuysmpVTxYAx8+aW11GV8vDXZ7IUXrMlmNWt6Ojrv5tYxBWPMImBRrm2f\nOn29D7jVnTEopYqXlSvh8cfhl1+sJS//9z+rFUVRnlvgSp4eaFZKKZfYvRueeQY++8y6G5g4Ee69\nF3x8PB1Z4aJJQSlVqKWmWusWTJhgzTl4+mkYNw4qVvR0ZIWTJgWlVKGUmWm1rX72WThwAAYPhvHj\ni+eEM1fSpKCUKnSWLrXGDVavttY//vJL6NDB01EVDW5tiKeUUq60eTP06wddu8Lx4zBnDvz2myYE\nV9KkoJTyekePwmOPQYsW1oSz//7Xmow2aJDOM3A1LR8ppbzW+fNWO4r//AdOnLD6Er30UtFb2Mab\naFJQSnkdYyAmBp58ErZsge7drZbWQUGejqzo0/KRUsqrJCRAly7Qv781x+Dbb2HxYk0IBUWTglLK\nK+zbB6NGQevWkJQEH30Ea9ZAr146blCQtHyklPKoM2esiWevvw4ZGdYymM88A5Urezqy4umydwoi\n8rCIVCmIYJRSxYfdbi1y07ix1ayuVy9Yv96anawJwXPyUz6qhbW+8jwR6elYOlMppa7a8uXQti0M\nHw7XXQcrVsDnn8MNN3g6MnXZpGCMeQ5oBEwGRgJbROQ1EdF/PqXUFdm2De68Ezp3hoMHrTuFP/+E\nm27ydGQqS74Gmo0xBjjg+MgAqgBfiMgbboxNKVVEHD9ujRU0awbff2/NO9i0CYYOhRL6uItXuexA\ns4g8CgwHDgM24EljTLqIlAC2AE+5N0SlVGGVnm61sH7hBWtW8siR8MorUKeOpyNTF5Ofp4+qAncY\nY3Y6bzTG2EXkdveEpZQqzIyBRYusu4ONGyEiwpp81qqVpyNTl5OfG7fvgKNZL0Skooi0AzDGbHBX\nYEqpwikpCXr0sNZFzsyEBQvgp580IRQW+UkKnwCpTq9THduUUirbgQMwdiyEhEBcHLz7LqxdC337\n6uSzwiQ/5SNxDDQD2WUjnfSmlALg7FkrAbz2GqSlwSOPwP/9H1St6unI1NXIz53CdhF5RER8HR+P\nAtvdHZhSyrsZA7NnQ9Om1gzkrl1h3Tp45x1NCIVZfpLC/UBHYC+wB2gHjHVnUEop7/b779CxI0RG\nWgngp5/g66+t2cmqcMvP5LVDxpjBxpiaxphaxphIY8yh/BzcMQN6k4hsFZFxebz/pIgkOj7Wikim\niOjfGEp5qeRkay3kjh1h506YMsUaP+jSxdORKVfJzzyFMsBooAVQJmu7Mebey3yfD/AR0B3rDmOl\niMQYY9Y7HeNN4E3H/n2AfxpjjuZ1PKWU55w8aa129s471mSz55+31jooX97TkSlXy0/5aCZQG+gB\n/AzUA07l4/vaAluNMduNMeeBOUC/S+x/DzA7H8dVShWQjAxr8lmjRjB+PNx9tzUT+aWXNCEUVflJ\nCjcaY/4POG2MmQ70xhpXuJy6wG6n13sc2/5GRPyAnsD8i7w/VkTiRCQuJSUlH6dWSl2rJUusuQX3\n3WeNFaxcCTNmQP36no5MuVN+kkK64/NxEQkEKgE1XRxHH+DXi5WOjDETjTFhxpiwGjVquPjUSiln\n69dbbax79LDWOvjiC6uraViYpyNTBSE/SWGiYz2F54AYYD3wej6+by/g/DdFPce2vAxGS0dKeVRK\nCvzjH9CyJfz6K7z5ppUg7ryzcE4+231iN2sOruF85nlPh1KoXHKg2dH07qQx5hiwHGh4BcdeCTQS\nkQCsZDAYiMzjHJWAzsDQKzi2UspFzp2DDz6wGtWlpsL991sN7ArjTfmRM0f4fP3nRCdF88uuXwDw\nLeFLi5otCK4VTEjtEEJqhxBcK5gqZXXtsLxcMik4Zi8/Bcy70gMbYzJE5CFgMeADTDHGrBOR+x3v\nf+rYdQCwxBhz+krPoZS6esbA/Pnw1FOwY4dVMpowwWpvXZicST9DzKYYZiXN4rut35Fhz6BZ9Wa8\nEvEKDas0ZM3BNSQeTGTxtsVMXz09+/uur3R9doLIShb+lf0p7uuIiVMHi7x3EBmP1TZ7LpD9i9tT\nj46GhYWZuLg4T5xaqSJj5Up4/HH45RcIDLQ6mN56q6ejyr8MewY/bf+J6KRovtr4FannU6lToQ73\nBN7DkKAhhNQOyfOX+4HUA6w+sJrEA4msPmh93nRkE3ZjB6BS6UoE1w4mpFaI9bl2CC1qtKB0ydIF\n/SO6nIisMsZcdmQoP0lhRx6bjTHmSkpJLqNJQamrt3u31ZLis8+gZk14+WW4914oWQi6mRlj+Gvv\nX8xKmsWcdXM4dPoQlUpX4s5mdzKk5RA6X98ZnxI+V3zcM+lnWHtorZUoDqwm8aD1+XS69TdwyRIl\naVa92d/uKqr5VXP1j+hWLksK3kaTglJXLjUV3njDKg/Z7dZdwrhxULGipyO7vM1HNhO9JppZa2ex\n9ehWSvmU4vbGtzMkaAi9GvWiTMkylz/IFbIbO9uObrvgjiLxQCJ7T+U8K1OvYj0rQTjdVTSs0pAS\n4p1LybnyTmF4XtuNMTOuMrZroklBqfzLzITp0+HZZ63W1oMHWzOT/f09Hdml7T+1n7nr5hKdFE3c\nvjgEIdw/nCFBQ7iz+Z1ULlPZI3GlnE5h9cHV2XcUiQcS2ZCygUyTCUD5UuWz7yayPgfWDKSsb1mP\nxOvMlUnhA6eXZYCuQLwx5q5rC/HqaFJQKn9iY607gsREaN8e3n4bOnTwdFQXd/LcSb7c8CXRSdEs\n3bEUu7HTqnYrhgQNYXDgYOpWzHPuq8elZaSx7tC6C+4oEg8kcuq81fihbMmyLBi8gO43dPdonG4r\nH4lIZWCOMabn1QZ3LTQpKHVpmzdbfYliYqBBA3j9dRg0yDvnGpzPPM93W74jOimahZsXkpaRRkDl\nACKDIhkSNIRmNQrZo1AOdmMn+Xgyqw+s5rnY5zhy5ghrHlhDzXKunvebf/lNClczvHQaCLiK71NK\nuYkx1pNEU6fCzJlQtqxVJnr0Uetrb2I3dlbsXEF0UjRfrP+CY2nHqO5XndGtRjMkaAjt67Uv9I+F\nlpASNKzSkIZVGtKoWiPaTGrDiK9H8G3kt1475pAlP11SFwJZtxMlgOZcxbwFpZTr7dxp9SOaPh22\nbbOa1I0ZY00+q1XL09FdaM3BNUSviWb22tnsPrkbP18/+jftz5CgIXRv2B1fH19Ph+gWgTUDeevW\nt/jHon/w3h/v8c8O//R0SJeUnzGFzk4vM4Cdxpg9bo3qErR8pIq706fhyy9h2jRYutTa1qULjBwJ\nd9wB5cp5MroL7Ty+k1lJs5i1dhZrD63FR3zocWMPhgQNoW+TvpQvVTxarRpjGDB3AIu2LOKPqD8I\nvS60wGNw5UBzALDfGJPmeF0WqGWMSXZFoFdKk4IqjoyBFSusO4J586xHTBs2tBLBsGHe9TRRXq0m\nOtTrwJCgIdzd4m5qlCuE/TNc4MiZIwR/Gky5UuVYNXZVgSdEV44pfI61HGeWTMe2NlcZm1Iqn5KT\nc8pD27db5aG777aSwU03ec/g8aVaTdwTdA8Nq3hkrqtXqeZXjc/u+Iwu07vw6HePMrnfZE+HlKf8\nJIWSjkVyADDGnBeRUm6MSali7fRpqyfRtGnWY6UAXbtaC9sMGOA95aGLtZp4tN2jl2w1UZyF+4fz\nzM3P8OqKV+l+Q3cGBw72dEh/k5+kkCIifY0xMQAi0g+rF5JSykXsduvpoWnT4PPPrfLQDTdYbSiG\nDYPrr/d0hBZjDCv3rSR6TTRz183l4OmDVCpdiUEtBjEkaAi3XH/LVbWaKE5e6PwCS3cs5b5v7qNd\n3XYEVPGuhznzM6ZwAxAN1HFs2gMMN8ZsdXNsedIxBVWU5C4PVaiQUx7q1Ml7ykOeaDVRlCUfTyb4\n02Ca12jO8pHLC+TJK5eNKRhjtgHtRaS843WqC+JTqthKTc0pDy1bZv3i79LF+8pDB1IPMGftnAta\nTUQERPD0TU9zR7M7PNZqoijwr+zPxNsnMnj+YF76+SVe6fKKp0PKlp95Cq8BbxhjjjteVwGeMMY8\n5+7glCoq7Hbr6aGs8tDp03DjjdbCNsOGWTOPvcHFWk1M6D7Bq1tNFEaDAgexeNtiXlvxGt0adiPc\nP9zTIQH5Kx8lGGNa5doWb4wp+Adt0fKRKlx27MgpD+3YYZWHBg2yykMdO3pHeehirSaGBA0hMiiy\n0LaaKAxSz6fSemJrTp8/zer7V7u1HbcrH0n1EZHSxphzjgOXBQr/ihNKuUle5aGuXa1B4wEDwM/P\n0xHmtJqYlTSLz9d/XiRbTRQG5UuVZ/ads2lva8/omNF8Negrj1/3/CSFaOAnEZkKCDASmH7J71Cq\nmLHbYflyKxF88YX3lofyajUxoOkAIoMii3SrCW8Wel0o47uN54klT/BJ3Cc82OZBj8aTn4Hm10Vk\nNdANqwfSYsBLHpBTyrO2b88pDyUnW+WhyEirPNShg3eUh3Ye38nstbOJToq+oNXE+G7j6dekH+VK\necnIdjH2WPvH+GH7Dzy++HFubnAzQbWCPBZLfrukHsRKCAOBHcB8t0WklJdLTbXuBqZNg59/tn7x\nd+sGr74K/ft7R3kor1YTHet35MPbPizWrSa8VQkpwbR+0wj+NJh75t/DyjErPbYwz0WTgog0Bu5x\nfBwG5mINTEcUUGxKeQ273UoA06fnlIcaNbISwbBhUL++pyO0BoxjNsUwY/UMvt/6Pen29OxWE5FB\nkV43SUpdqFb5WkzvP52e0T15YskTfNz7Y4/Ecak7hY3ACuD2rIlqIuLdPV+VcrHt261EMH261aa6\nYkXvKw/oOZwIAAAeDUlEQVRtPLwRW7yNGatnkHImhToV6vBIu0e01UQh1OPGHjzR4Qne+v0tbr3h\nVvo37V/gMVwqKdwBDAZiReR7YA7WQHO+iUhP4D3AB7AZY8bnsU848C7gCxw2xnTOvY9SBenUqZzy\n0PLl1i/+7t2tRWv69/eORWvOpJ/h83WfY0uw8cuuXyhZoiR9m/QlqlUUt95wq7aaKMRe6/oa32z+\nhrd/f9u7koIx5mvgaxEpB/QDHgNqisgnwFfGmCWXOrCI+AAfAd2xWmOsFJEYY8x6p30qAx8DPY0x\nu0TEc2vVqWItqzyU9fTQmTPQuDG89hoMHeod5SGA+P3x2OJtRCdFc/LcSRpVbcTr3V5nePBwapev\n7enwlAuU8ilFn8Z9eO/P9ziTfgY/34IdpMrP00engVnALMds5oHAv4FLJgWgLbDVGLMdQETmYCWX\n9U77RAJfGmN2Oc516Ip/AqWuwbZtOU8PZZWHhg61ykPt23tHeeh42nFmJc3CFm8j4UACZUqWYWDz\ngUSFRnFzg5u1PFQERQREMOH3Cfy2+ze6NexWoOe+ojWajTHHgImOj8upC+x2er0HaJdrn8aAr4gs\nAyoA7xljZuQ+kIiMBcYCNPCWB75VoXXqlNVqYto0q/WEN5aHjDH8susXbAk2Pl/3OWczzhJcK5gP\nb/uQyKBIqpSt4ukQlRvd3OBmfMSH2B2x3p0U3HT+1kBXoCzwu4j8YYzZ7LyTMSY7EYWFhV26L4dS\nebDbrdnF06ZZs43PnIEmTaxEMHQo1Kvn6Qgth04fYsbqGdjibWw6sokKpSowPHg4Y0LHEHpdqN4V\nFBMVSlcgrE4YscmxBX5udyaFvYBzJbaeY5uzPcARR4nqtIgsB4KBzSjlAtu25Tw9tGsXVKpkPUI6\nciS0a+cd5aFMeyY/bP8BW7yNBZsWkGHPoFP9Toy7aRwDmw/UyWXFVJeALrz525ucOneKCqUrFNh5\n3ZkUVgKNHGs878V6kiky1z4LgA9FpCRQCqu89I4bY1LFwMmTVnlo+vSc8tCtt8Lrr0O/ft5RHgLY\ndWIXUxOmMiVxCrtO7KJa2Wo80vYRRoeOpnmN5p4OT3lYhH8E//3lv/yy6xdua3RbgZ3XbUnBGJMh\nIg9htcXwAaYYY9aJyP2O9z81xmxwPO66BrBjPba61l0xqaLLbreWrswqD509653lofOZ5/lm8zdM\nip/E4q2LMRi6N+zOhO4T6NukL6VLaq9JZenUoBO+JXyJTY4t0KRw2dbZ3kZbZytnW7dadwQzZuSU\nh+65xyoPtW3rHeUhgE2HNzE5YTLTV0/n0OlD1K1Ql3tb3cuokFE601hd1M1TbyYtI42VY1Ze87Fc\n2TpbKa+SVR6aNs1a17hECas89MYb0Lev95SHzqSfYf76+UyKn8SKXSvwER/6NOlDVKsoetzYg5Il\n9H8/dWkR/hG8uuJVTqSdoFKZSgVyTv2vUhUKdjssXWolgi+/tMpDTZvC+PFWeaiuFy0IlnggkUmr\nJhGdFM2Jcye4seqNjO86nhEhI3SCmboiEf4RvLz8ZZbvXE6fJn0K5JyaFJRX27Ilpzy0e7dVHhox\nwvvKQyfSTjB77Wxs8TZW7V9FaZ/S3NX8LqJCo+h8fWd9lFRdlQ71O1DapzSxybGaFFTxdeJETnno\n11+t8lCPHjBhglUeKlPG0xFajDH8tvs3JsVPYt66eZzNOEtQzSDe7/k+Q1sO1Qlm6pqVKVmGjvU7\nFuh8BU0KyitkZuY8PZRVHmrWzHqMdOhQqFPH0xHmSDmdYk0wS7Cx8fBGypcqz7CWw4gKjSKsTpje\nFSiXivCP4Pllz3PkzBG3ruGcRZOC8qjc5aHKla3S0MiR0KaN95SH7MbOj9t/xBZv4+uNX5NuT6dD\nvQ5M7juZu1vcTflS5T0doiqiIgIiYBn8vPNn7mh2h9vPp0lBFbgTJ2DePOuu4LffrPJQz57eVx4C\n2HNyD1MTpjI5YTI7T+ykWtlqPNT2IUa3Gk2Lmi08HZ4qBtrWbYufrx+xO2I1KaiiIzPzwqeH0tKs\n8tAbb8CQId5VHkrPTOebzd9gS7Dx/dbvsRs73Rp24/Vur9O/aX+dYKYKVCmfUnSq36nAxhU0KSi3\n2rw5pzy0Z49VHrr3Xqs8FBbmPeUhgC1HtjA5YTLTEqdx8PRB6lSow9M3Pc29re6lYZWGng5PFWNd\nArrw9E9Pc+j0IWqWc++yM5oUlMudOAFz51rJwLk89Pbb0KePd5WHzqaf5csNXzIpfhI/7/wZH/Gh\nd+PejAkdQ88be+oEM+UVIvwjAFiWvIy7W9zt1nPpf/HKJTIz4aefrPLQV19Z5aHmzeHNN63y0HXX\neTrCC60+sBpbvI3Pkj7jeNpxGlZpyGtdXmNEyAjqVPCiWpZSQOs6ralQqgKxO2I1KSjvtmlTTnlo\n716oUgVGj7bKQ61be1d56OS5k8xZO4dJ8ZOI2xdHKZ9S3NnsTqJCowj3D6eElPB0iErlqWSJktx8\n/c0FMq6gSUFdsePHc54e+v138PGxykPvvmuVh0p70TisMYbf9/yOLd7G3HVzOZN+hsCagbzX8z2G\nBA0pkOe+lXKFCP8IFm1ZxL5T+9x6N6tJQeVLZib8+GNOeejcOWjRwnvLQ4fPHGbm6pnYEmysT1lP\nOd9yRAZGEhUaRdu6bXWCmSp0ssYVYnfEMqTlELedR5OCuqSNG63y0MyZOeWhqCjvLA/ZjZ2lO5Yy\nKX4SX2/8mvOZ52lXtx22PjbubnF3ga5epZSrhdQOoXKZysQma1JQBez4cevpoWnT4I8/rPLQbbfB\ne+/B7bd7V3kIrAlm0xKnMTlhMsnHk6lSpgoPhD3A6FajCaoV5OnwlHIJnxI+dL6+s9vHFTQpKODi\n5aEJE6zyUG0v6/icnpnOoi2LsCXYWLRlEXZjp0tAF17r8hoDmg2gTEkveu5VKReJ8I9gwaYF7Dqx\niwaVGrjlHJoUirms8tCMGbBvH1StCmPGWOWh0FDvKg8BbD26lcnxk5m2ehoHUg9wXfnrGNdpHPe2\nupcbqt7g6fCUcquIgJxxhREhI9xyDk0KxdCxYznloT//tMpDvXrB++97Z3koLSONLzd8iS3eRmxy\nLCWkBL0b9SYqNIpejXrpBDNVbATWDKRa2WrEJmtSUNcoMxN++MFKBF9/bZWHAgPhrbes8lCtWp6O\n8O+SDiZhi7cxc81MjqUdI6ByAK9EvMLIkJHUrehFS60pVUBKSAnC/cNZumMpxhi3PEWnSaGI27Ah\n5+mhrPLQ2LFWeahVK+8rD506d4o5a+dgS7Dx196/KOVTigFNBzAmdAwRARE6wUwVexH+EczfMJ/t\nx7a7pWTq1qQgIj2B9wAfwGaMGZ/r/XBgAbDDselLY8x/3BlTcXDsGMyZY90V/PVXTnnogw+gd2/v\nKw8ZY/hz75/Y4m3MWTuH0+mnaV6jOe/0eIehLYdS3a+6p0NUymt0CegCQGxybOFKCiLiA3wEdAf2\nACtFJMYYsz7XriuMMbe7K47iIiMjpzy0YIFVHgoKsprQRUZ6Z3noyJkjfLbmM2wJNtYeWoufrx+D\nWwxmTOsxtKvbTieYKZWHptWbUrt8bWKTY4kKjXL58d15p9AW2GqM2Q4gInOAfkDupKCuwfr1OeWh\n/fuhWjW47z6rPBQS4n3lIbuxE7sjFluCjS83fMn5zPO0qdOGibdPZFDgICqWrujpEJXyaiJCuH84\nsTti3TKu4M6kUBfY7fR6D9Auj/06isgaYC/wL2PMOjfGVCTkVR7q3dtKBL17Q6lSno7w7/ad2pc9\nwWz7se1ULlOZ+1rfx+hWowmuHezp8JQqVCL8I5izdg6bj2ymSfUmLj22pwea44EGxphUEekFfA00\nyr2TiIwFxgI0aOCeCRveLiMDlizJKQ+dP+/95aEMe4Y1wSzexrdbvsVu7IT7h/NyxMsMaDqAsr5l\nPR2iUoVSdh+k5NhClRT2AvWdXtdzbMtmjDnp9PUiEflYRKobYw7n2m8iMBEgLCzMuC9k77NuXU55\n6MABqzx0//3eWx4C2HZ0G1MSpjA1cSr7U/dTq1wtnur4FPe2updG1f6W85VSV+jGqjdSt0Jdlu5Y\nyv1h97v02O5MCiuBRiISgJUMBgORzjuISG3goDHGiEhboARwxI0xFQpHj+aUh1auhJIlc8pDvXp5\nZ3koLSONrzd+jS3exk87fqKElOC2G28jKjSK3o164+vj6+kQlSoyRIQuAV34fuv3Lh9XcFtSMMZk\niMhDwGKsR1KnGGPWicj9jvc/Be4CHhCRDOAsMNgYU6zuBLLkVR5q2RLeeccqD9V077KsV23tobXZ\nE8yOnj2Kf2V/Xo54mZEhI6lXsZ6nw1OqyIrwj2DmmpmsS1lHYM1Alx3XrWMKxphFwKJc2z51+vpD\n4EN3xuDt1q2zEsFnn1nloerV4YEHcspD3ij1fCpz187FlmDjjz1/4FvClwHNBhDVKoquDbvqBDOl\nCoBzH6RCkxRU3o4ehdmzrWQQF1c4ykPGGFbuW4kt3sbstbNJPZ9Ks+rNeOvWtxjWchg1ytXwdIhK\nFSv+lf3xr+xPbHIsD7d72GXH1aRQQDIyYPFiKxHExFjloZAQawnLyEio4aW/U4+ePWpNMIu3kXQo\nCT9fPwa1GERUaBQd6nXQCWZKeVBWK227sbvsDl2TgputXZvz9NDBg1Z56MEHYcQI7y0P2Y2dn5N/\nxpZgY/76+ZzLPEdYnTA+7f0pgwMHU6lMJU+HqJTCSgpTE6ey5uAaQmq75heKJgU3OHIkpzy0apVV\nHrr9dqs8dNtt3lkeAth/an/2BLNtx7ZRqXQlokKjiAqNctl/cEop18kaV1i6Y6kmBW+TkQHff59T\nHkpPt7qQvvce3HOP95aHMuwZfL/1e2zxNr7Z/A2ZJpPO13fmxfAXubPZnTrBTCkvVq9iPRpVbURs\nciyPd3jcJcfUpHCNkpKs8tBnn1nloRo14KGHrPJQsBd3b9hxbEf2BLO9p/ZSs1xNnujwBKNDR9O4\nWmNPh6eUyqcI/wjmrJtDhj3DJQtOaVK4CnmVh/r0ySkP+XrpPK1zGeesCWYJNn7c/iOC0PPGnnxw\n2wfc3vh2nWCmVCEUERDBxPiJJOxPoE3dNtd8PE0K+ZSenlMeWriw8JSHANanrMcWb2PG6hkcOXuE\nBpUa8FL4S4wKGUX9SvUvfwCllNcK9w8HrD5ImhQKQFJSzuSyQ4cKT3no9PnTzFs3D1uCjd92/4Zv\nCV/6Ne3HmNAxdA3oik8JH0+HqJRygdrla9OsejNik2N5qtNT13w8TQp5OHw4pzwUH2+Vg7LKQz17\nem95yBhD3L647Almp86fokm1JkzoPoFhwcOoWc5Le2Uopa5JhH8E01dPJz0z/ZrLwJoUHPIqD4WG\nwvvvW+Wh6l68IuSxs8eITorGFm9j9cHVlC1Zlrtb3E1UaBSd6nfSCWZKFXFdArrwcdzHrNy3ko71\nO17TsYp9UlizxkoE0dFWeahmTXj4Yas81LKlp6O7OGMMy3cuZ1L8JL5Y/wXnMs8Rel0oH/f6mMig\nSJ1gplQx0tm/M2D1QdKkcBUOH4ZZs6xkkJBQeMpDAAdSDzA9cTqTEyaz5egWKpWuxOhWoxkdOprQ\n60I9HZ5SygOq+1WnZa2WxCbH8uwtz17TsYpNUkhPh+++sxLBN99Yr1u3hg8+sMpD1ap5OsKLy7Rn\nsnjbYmzxNhZuXkiGPYObG9zMc7c8x13N78LP18/TISqlPCzCP4L/rfof5zLOUbpk6as+TpFPCqtX\n50wuS0mxykOPPGKVh4KCPB3dpSUfT86eYLbn5B5q+NXgsXaPMTp0NE2rN/V0eEopL9K/aX/sxs7p\n9NOaFHJLSckpDyUmWuWgvn2t8lCPHt5dHjqfeZ4FGxdgS7Dxw7YfAOhxYw/e7fEufZr0oZSPlzZO\nUkp5VLh/ePachWtRZJJCejosWpRTHsrIgLAw+PBDGDzYu8tDABtSNjA5YTLTV0/n8JnD1K9Yn+c7\nP8+9re6lQaUGng5PKVVMFPqksHp1ztNDKSlQqxY89phVHgp03WJEbnH6/Gk+X/85tngbv+7+lZIl\nStK3SV/GhI6he8PuOsFMKVXgCmVSyF0eKlXqwvJQSS/+qYwxxO+PxxZvY9baWZw8d5LG1RrzRrc3\nGB48nFrla3k6RKVUMebFvz7ztm0b1KlT+MpDx9OOE70mGluCjcQDiZQpWYaBzQcyJnQMNzW4SSeY\nKaW8QqFLCqmphac8ZIxhxa4V2OJtfL7+c9Iy0gipHcJHvT4iMiiSymUqezpEpZS6QKFLCi1bwptv\nejqKSzuYepAZq2dgS7Cx+chmKpSqwMjgkUSFRtG6TmtPh6eUUhfl1qQgIj2B9wAfwGaMGX+R/doA\nvwODjTFfXPqYLg/TJTLtmSzZtgRbgo2YTTFk2DPoVL8TT9/0NAObD6RcqXKeDlEppS7LbUlBRHyA\nj4DuwB5gpYjEGGPW57Hf68ASd8XiTjuP72Rq4lSmJExh98ndVPerzqPtHmV0q9E0q9HM0+EppdQV\nceedQltgqzFmO4CIzAH6Aetz7fcwMB+49tUhCsj5zPMs3LQQW4KNxVsXA9D9hu68detb9GvaTyeY\nKaUKLXcmhbrAbqfXe4B2zjuISF1gABBBIUgKGw9vZHK8NcEs5UwK9SrW4/9u+T9GtRqFf2V/T4en\nlFLXzNMDze8C/zbG2C/1SKaIjAXGAjRoULCze8+kn+GL9V9gi7exYtcKSpYoSZ/GfYgKjaLHDT10\ngplSqkhxZ1LYCzgvAFzPsc1ZGDDHkRCqA71EJMMY87XzTsaYicBEgLCwMOO2iJ0k7E9gUvwkopOi\nOXnuJDdWvZHxXcczImQEtcvXLogQlFKqwLkzKawEGolIAFYyGAxEOu9gjAnI+lpEpgHf5E4IBelE\n2glmJc3ClmAjfn88ZUqW4a7mdxHVKopbrr9FJ5gppYo8tyUFY0yGiDwELMZ6JHWKMWadiNzveP9T\nd537Shhj+HX3r9jibcxbN4+zGWdpWaslH9z2AUOChlClbBVPh6iUUgXGrWMKxphFwKJc2/JMBsaY\nke6MJbdDpw9ZE8zibWw6sonypcozrOUwxrQeQ+vrWutdgVKqWPL0QHOBshs7P2z7AVuCjQUbF5Bu\nT6dj/Y5M6TSFgS0GUr5UeU+HqJRSHlUsksLuE7uzJ5jtPLGTamWr8VDbhxjdajQtarbwdHhKKeU1\nimxSSM9MZ+HmhdjibXy/9XsMhm4Nu/F6t9fp37T/NS1Xp5RSRVWRSwqbj2xmcvxkpq2exqHTh6hT\noQ7P3vws97a6l4AqAZc/gFJKFWNFIimcTT/L/A3zmRQ/ieU7l+MjPtze+HaiQqPoeWNPSpYoEj+m\nUkq5XaH+bZl4IBFbvI3P1nzGiXMnuKHKDfy3638ZETyC6ypc5+nwlFKq0Cl0SSHTZPK/uP9hS7AR\nty+O0j6lubP5nUS1iqKzf2dKSAlPh6iUUoWWGFMgXSNcxqeuj7GPtRNYM5AxoWMY2nIoVctW9XRY\nSinl1URklTEm7HL7Fbo7haplq/Jt1Le0qdNGJ5gppZSLFbqkcH3l62lbt62nw1BKqSJJC/BKKaWy\naVJQSimVTZOCUkqpbJoUlFJKZdOkoJRSKpsmBaWUUtk0KSillMqmSUEppVS2QtfmQkROAZs8HYeX\nqA4c9nQQXkKvRQ69Fjn0WuRoYoypcLmdCt2MZmBTfvp3FAciEqfXwqLXIodeixx6LXKISFx+9tPy\nkVJKqWyaFJRSSmUrjElhoqcD8CJ6LXLotcih1yKHXosc+boWhW6gWSmllPsUxjsFpZRSbuL1SUFE\nkkUkSUQSs0bPRaSqiPwgIlscn6t4Os6CICI+IpIgIt84Xhe76yAiZUTkLxFZLSLrROQlx/bieC3q\ni0isiKx3XItHHduL3bUAEJEpInJIRNY6bSuW18KZiPQUkU0islVExl1uf69PCg4RxpgQp0fLxgE/\nGWMaAT85XhcHjwIbnF4Xx+twDuhijAkGQoCeItKe4nktMoAnjDHNgfbAP0SkOcXzWgBMA3rm2lZc\nrwVg/SEJfATcBjQH7nH8N3JRhSUp5NYPmO74ejrQ34OxFAgRqQf0BmxOm4vddTCWVMdLX8eHoXhe\ni/3GmHjH16ew/mCoSzG8FgDGmOXA0Vybi+W1cNIW2GqM2W6MOQ/MwbomF1UYkoIBfhSRVSIy1rGt\nljFmv+PrA0Atz4RWoN4FngLsTtuK43XIKqMlAoeAH4wxf1JMr0UWEfEHWgHF/lrkUtyvRV1gt9Pr\nPY5tF1UYZjTfZIzZKyI1gR9EZKPzm8YYIyJF+hEqEbkdOGSMWSUi4XntUxyuQxZjTCYQIiKVga9E\nJDDX+8XmWgCISHlgPvCYMeakiGS/V9yuxaXotcgfr79TMMbsdXw+BHyFdTt0UESuA3B8PuS5CAtE\nJ6CviCRj3f51EZHPKH7X4QLGmONALFYduVheCxHxxUoI0caYLx2bi+W1uIjifi32AvWdXtdzbLso\nr04KIlJORCpkfQ3cCqwFYoARjt1GAAs8E2HBMMY8bYypZ4zxBwYDS40xQylm1wFARGo47hAQkbJA\nd2AjxfNaCDAZ2GCMedvprWJ3LS6huF+LlUAjEQkQkVJYvz9iLvUNXj15TUQaYt0dgFXqmmWMeVVE\nqgHzgAbATuBuY0zuAaYiyVE++pcx5vbieB1EpCXWgKEP1h8184wx/ymm1+ImYAWQRM5Y0zNY4wrF\n6loAiMhsIByrM+pB4AXga4rhtXAmIr2wxiR9gCnGmFcvub83JwWllFIFy6vLR0oppQqWJgWllFLZ\nNCkopZTKpklBKaVUNk0KSimlsmlSUB4lIkZE3nJ6/S8RedFFx54mIne54liXOc9AEdkgIrEuONZ/\nRKTbZfZ5UUT+lcd2f+cOoUpdDU0KytPOAXeISHVPB+JMRK6kBcxoYIwxJuJaz2uMed4Y8+O1Hudq\nODpqqmJOk4LytAysZQL/mfuN3H/pi0iq43O4iPwsIgtEZLuIjBeRIY51FpJE5Aanw3QTkTgR2ezo\nIZXVUO9NEVkpImtE5D6n464QkRhgfR7x3OM4/loRed2x7XngJmCyiLyZa/9wEVkmIl+IyEYRiXbM\nQkZEWjt+hlUistipFUP2zywivRzft0pE3hfHOhoOzR3H3i4ijzhtL+k4zwbHef0cx+oq1locSWKt\nO1DasT1ZRF4XkXhgoIg8Itb6DGtEZE4+/v1UUWOM0Q/98NgHkApUBJKBSsC/gBcd700D7nLe1/E5\nHDgOXAeUxurl8pLjvUeBd52+/3usP34aYXWILAOMBZ5z7FMaiAMCHMc9DQTkEWcdYBdQA2t2/VKg\nv+O9ZUBYHt8TDpzA6jdTAvgdK4H4Ar8BNRz7DcKaaZr9Mzvi3J0VCzAb+Mbx9YuO7y+NNXv3iOOY\n/lhdhTs59pviuJ5Zx2rs2D4Dq3kejuv+lFPM+4DSjq8re/q/D/0o+A+9U1AeZ4w5ifWL6pHL7etk\npbHWEzgHbAOWOLYnYf1yzDLPGGM3xmwBtgNNsXpoDRer/fafQDWspAHwlzFmRx7nawMsM8akGGMy\ngGjglnzE+ZcxZo8xxg4kOmJrAgRidf1NBJ7DShzOmgLbnWKZnev9b40x54wxh7GavGW1hN5tjPnV\n8fVnWEmoCbDDGLPZsX16rtjnOn29BogWkaFYd3GqmCkMrbNV8fAuEA9MddqWgaPEKSIlgFJO751z\n+tru9NrOhf9d5+7jYgABHjbGLHZ+w9FX6vTVhX9RznFmOmITYJ0xpoOLjwt5/7yX4/wz98ZKGH2A\nZ0UkyJEEVTGhdwrKKxirSdk8rEHbLMlAa8fXfbFKJFdqoIiUcIwzNAQ2AYuBBxxtpxGRxo4uvJfy\nF9BZRKo7BmTvAX6+inhwxFBDRDo4zu8rIi3y2KehWIvngFViyo8GWccFIoFfHMfyF5EbHduH5RW7\nI/HWN8bEAv/GKueVz+d5VRGhSUF5k7ewauRZJmH9Il4NdODq/orfhfUL/TvgfmNMGtaSpuuBeMcj\nnP/jMnfNxlq9axzW+g2rgVXGmKtqw2ysZRHvAl53/GyJQMdc+5wFHgS+F5FVwCms8YnL2YS1VvMG\noArwieNnHgV8LiJZHVU/zeN7fYDPHPskAO8ba80KVYxol1SlvJSIlDfGpDqeWPoI2GKMecfTcami\nTe8UlPJeYxwD0euwSjn/83A8qhjQOwWllFLZ9E5BKaVUNk0KSimlsmlSUEoplU2TglJKqWyaFJRS\nSmXTpKCUUirb/wM4JD8Z2TgR4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa3cd278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.108195\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.062640\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.107503\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.022361\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.028250\n",
      "C: 0.010000, gamma: 0.010000, average score: 0.003935\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.095616\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.025432\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.113613\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.181113\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.507237\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.454607\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.171414\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.580755\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.657966\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.692517\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.536646\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.585686\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.677555\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.713445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.028411, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.039365, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.002067, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.025747, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.037420, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.000287, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.014399, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.028293, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.007648, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.016610, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.028944, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.006597, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.025465, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.037252, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.000104, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.000048, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.018425, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.017947, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.103404, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.065867, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.091493, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.085218, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.053129, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.080490, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.002576, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.016783, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.019779, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.212102, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.132413, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.168309, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.557564, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.485636, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.495322, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.541330, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.474077, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.478685, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.229287, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.147293, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.182036, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.618184, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.570064, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.558647, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.652293, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.700897, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.661366, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.683484, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.762761, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.648435, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.612329, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.573362, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.565323, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.621482, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.635555, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.630771, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.648854, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.700340, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.661539, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.670374, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.767180, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.700954, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712411732767\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/14_grid_search.py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
