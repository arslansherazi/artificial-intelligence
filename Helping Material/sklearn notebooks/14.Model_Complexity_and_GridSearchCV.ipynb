{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.482870\n",
      "n_neighbors: 3, average score: 0.698497\n",
      "n_neighbors: 5, average score: 0.781932\n",
      "n_neighbors: 10, average score: 0.727549\n",
      "n_neighbors: 20, average score: 0.641479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npVQGTQpKKaUyaFJQSimV4f8BxfDWzvHHGCMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9f60278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.055171\n",
      "C: 0.001000, gamma: 0.010000, average score: 0.001434\n",
      "C: 0.001000, gamma: 0.100000, average score: 0.007884\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.013389\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.061055\n",
      "C: 0.010000, gamma: 0.010000, average score: 0.021343\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.086728\n",
      "C: 0.010000, gamma: 1.000000, average score: -0.003939\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.123074\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.170594\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.456092\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.408771\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.057175\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.579429\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.637037\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.693333\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.584058\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.619630\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.658585\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.786291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.126688, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.155018, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.000310, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.124434, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.152372, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .............. C=0.001, gamma=0.01, score=0.001556, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.114906, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.142107, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.009976, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.116312, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.145768, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.008936, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.124212, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.152064, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .............. C=0.01, gamma=0.001, score=0.001737, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.102671, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.120882, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.020505, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.004134, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ............... C=0.01, gamma=0.1, score=-0.004876, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.100509, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.003005, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.028507, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.089831, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.100531, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.116823, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.022346, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.121455, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.084916, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.174551, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.502089, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.444941, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.526209, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.483717, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.376553, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.513004, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.139030, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.089638, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.181262, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.554813, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.544534, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.607583, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.653947, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.628933, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.699850, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.661570, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.675790, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=1, score=0.756378, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.556701, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.541770, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.613565, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.570523, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.581809, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.663061, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.643102, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.634882, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.708672, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.672608, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.651290, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.797522, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706794596527\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
